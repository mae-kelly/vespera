import os
import torch
import platform

MODE = os.getenv("MODE", "dry")
LIVE_MODE = MODE == "live"
ASSETS = ["BTC", "ETH", "SOL"]

SIGNAL_CONFIDENCE_THRESHOLD = 0.7
POSITION_SIZE_PERCENT = 2.0
MAX_OPEN_POSITIONS = 3
MAX_DRAWDOWN_PERCENT = 10.0
COOLDOWN_MINUTES = 5

OKX_API_LIMITS = {
    "orders_per_second": 20,
    "requests_per_second": 10,
    "max_position_size": 50000
}

DISCORD_WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL")
DISCORD_USER_ID = os.getenv("DISCORD_USER_ID")

def setup_gpu_acceleration():
    system = platform.system()
    machine = platform.machine()
    
    print(f"üîç Detecting hardware: {system} {machine}")
    
    if torch.cuda.is_available():
        device_name = torch.cuda.get_device_name(0)
        print(f"üöÄ CUDA GPU detected: {device_name}")
        
        if "A100" in device_name:
            print("‚ö° A100 optimization enabled")
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            torch.backends.cudnn.benchmark = True
            torch.cuda.empty_cache()
            return {"type": "cuda_a100", "device": "cuda", "optimized": True}
        else:
            print(f"‚úÖ CUDA GPU acceleration enabled: {device_name}")
            torch.backends.cudnn.benchmark = True
            return {"type": "cuda_standard", "device": "cuda", "optimized": True}
    
    elif system == "Darwin":
        if torch.backends.mps.is_available() and torch.backends.mps.is_built():
            if machine == "arm64":
                print("üçé Apple Silicon Metal GPU (MPS) acceleration enabled")
            else:
                print("üçé Intel Mac Metal GPU (MPS) acceleration enabled")
            return {"type": "metal_mps", "device": "mps", "optimized": True}
        else:
            print("üçé macOS detected but Metal Performance Shaders not available")
            print("   Checking for discrete GPU support...")
            if torch.cuda.is_available():
                device_name = torch.cuda.get_device_name(0)
                print(f"üöÄ External GPU detected: {device_name}")
                return {"type": "cuda_mac", "device": "cuda", "optimized": True}
            else:
                print("   No GPU acceleration available - using optimized CPU")
                return {"type": "cpu_mac", "device": "cpu", "optimized": False}
    
    else:
        print("‚ö†Ô∏è No GPU acceleration available - using CPU")
        return {"type": "cpu", "device": "cpu", "optimized": False}

def validate_config():
    errors = []
    
    if SIGNAL_CONFIDENCE_THRESHOLD <= 0 or SIGNAL_CONFIDENCE_THRESHOLD > 1:
        errors.append("SIGNAL_CONFIDENCE_THRESHOLD must be between 0 and 1")
    
    if POSITION_SIZE_PERCENT <= 0 or POSITION_SIZE_PERCENT > 100:
        errors.append("POSITION_SIZE_PERCENT must be between 0 and 100")
    
    if MAX_OPEN_POSITIONS <= 0:
        errors.append("MAX_OPEN_POSITIONS must be positive")
    
    if not ASSETS or len(ASSETS) == 0:
        errors.append("ASSETS list cannot be empty")
    
    return errors

GPU_CONFIG = setup_gpu_acceleration()
GPU_AVAILABLE = GPU_CONFIG["optimized"]
DEVICE = GPU_CONFIG["device"]

config_errors = validate_config()
if config_errors:
    print("‚ùå CONFIGURATION ERRORS:")
    for error in config_errors:
        print(f"   - {error}")
    print("‚ùå Fix configuration before starting system!")
else:
    print(f"‚úÖ Config validated - GPU: {GPU_CONFIG['type']}, Device: {DEVICE}, Assets: {ASSETS}, Mode: {MODE}")
