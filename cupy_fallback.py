import torch
import warnings
import platform
import os

warnings.filterwarnings("ignore", category=UserWarning)

def get_optimal_device():
    """Intelligent device selection with comprehensive testing"""
    system = platform.system()
    
    if torch.cuda.is_available():
        try:
            test_tensor = torch.randn(10, device='cuda')
            _ = torch.sum(test_tensor)
            return 'cuda'
        except:
            pass
    
    if system == "Darwin":
        if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
            try:
                test_tensor = torch.randn(10, device='mps')
                _ = torch.sum(test_tensor)
                return 'mps'
            except Exception as e:
                try:
                    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'
                    test_tensor = torch.randn(5, device='mps')
                    _ = torch.sum(test_tensor)
                    return 'mps'
                except:
                    pass
    
    return 'cpu'

DEVICE = get_optimal_device()

def array(data, dtype=None):
    """Create tensor from data on optimal device with error handling"""
    try:
        if isinstance(data, (list, tuple)):
            tensor_data = torch.tensor(data, dtype=torch.float32 if dtype is None else dtype)
        else:
            tensor_data = torch.as_tensor(data, dtype=torch.float32 if dtype is None else dtype)
        
        if DEVICE != 'cpu':
            try:
                return tensor_data.to(DEVICE)
            except:
                global DEVICE
                DEVICE = 'cpu'
                return tensor_data
        return tensor_data
    except Exception as e:
        return torch.tensor([0.0], dtype=torch.float32)

def zeros(shape, dtype=torch.float32):
    """Create zero tensor on optimal device with fallback"""
    try:
        return torch.zeros(shape, dtype=dtype, device=DEVICE)
    except:
        return torch.zeros(shape, dtype=dtype, device='cpu')

def ones(shape, dtype=torch.float32):
    """Create ones tensor on optimal device with fallback"""
    try:
        return torch.ones(shape, dtype=dtype, device=DEVICE)
    except:
        return torch.ones(shape, dtype=dtype, device='cpu')

def log(x):
    return torch.log(x)

def diff(x, n=1):
    return torch.diff(x, n=n)

def sum(x, axis=None):
    if axis is None:
        return torch.sum(x)
    else:
        return torch.sum(x, dim=axis)

def min(x, axis=None):
    if axis is None:
        return torch.min(x)
    else:
        return torch.min(x, dim=axis)[0]

def max(x, axis=None):
    if axis is None:
        return torch.max(x)
    else:
        return torch.max(x, dim=axis)[0]

def mean(x, axis=None):
    if axis is None:
        return torch.mean(x)
    else:
        return torch.mean(x, dim=axis)

def where(condition, x, y):
    return torch.where(condition, x, y)

def all(x):
    return torch.all(x)

def any(x):
    return torch.any(x)

class RandomModule:
    @staticmethod
    def normal(mean=0.0, std=1.0, size=None):
        try:
            if size is None:
                return torch.normal(mean, std, size=(1,), device=DEVICE).item()
            else:
                return torch.normal(mean, std, size=size, device=DEVICE)
        except:
            if size is None:
                return torch.normal(mean, std, size=(1,), device='cpu').item()
            else:
                return torch.normal(mean, std, size=size, device='cpu')
    
    @staticmethod
    def exponential(scale=1.0, size=None):
        try:
            if size is None:
                return torch.exponential(torch.tensor([scale], device=DEVICE)).item()
            else:
                return torch.exponential(torch.full(size, scale, device=DEVICE))
        except:
            if size is None:
                return torch.exponential(torch.tensor([scale], device='cpu')).item()
            else:
                return torch.exponential(torch.full(size, scale, device='cpu'))

random = RandomModule()

def get_default_memory_pool():
    class SmartMemoryPool:
        def set_limit(self, size):
            pass
        def free_all_blocks(self):
            if torch.cuda.is_available():
                try:
                    torch.cuda.empty_cache()
                except:
                    pass
            elif DEVICE == 'mps':
                try:
                    torch.mps.empty_cache()
                except:
                    pass
    return SmartMemoryPool()

class cuda:
    class Device:
        def __init__(self, device_id=0):
            self.device_id = device_id
        
        def use(self):
            if torch.cuda.is_available():
                try:
                    torch.cuda.set_device(self.device_id)
                except:
                    pass

def fuse():
    def decorator(func):
        return func
    return decorator

device_names = {
    'cuda': 'CUDA GPU',
    'mps': f'Apple {"Silicon" if platform.machine() == "arm64" else "Intel"} Metal GPU',
    'cpu': 'Optimized CPU'
}

print(f"âœ… Smart PyTorch fallback loaded - Active device: {device_names.get(DEVICE, DEVICE)}")
